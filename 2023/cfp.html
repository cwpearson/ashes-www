---
layout: default
title: AsHES Workshop
---

<div id="sub-frame">
<h1>Workshop Scope and Goals</h1>
<div id="description">

  <p>The current computing landscape has gone through an ever-increasing rate of change and innovation. This change has been driven by the relentless need to improve the energy-efficient, memory, and compute throughput at all levels of the architectural hierarchy. Although the amount of data that must be organized by today's systems posed new challenges to the architecture, which can no longer be solved with classical, homogeneous design. Improvements in all those areas have led Heterogeneous systems to become the norm rather than the exception.</p>

  <p>Heterogeneous computing leverages a diverse set of computing (CPU, GPU, FPGA, TPU, DPU, etc.) and Memory (HBM, Persistent Memory, Coherent PCI protocols, etc.), hierarchical systems and units to accelerate the execution of a diverse set of applications. Emerging and existing areas such as AI, BigData, Cloud Computing, Edge-Computing, Real-time systems, High-Performance Computing, and others have seen a real benefit due to Heterogenous computer architectures. In addition, a new wave of accelerators based on dataflow architecture instead of the traditional von Neumann is sure to bring additional challenges and opportunities.</p>

  <p>These new heterogeneous architectures often also require the development of new applications and programming models, to satisfy these new architectures and to fully utilize these capacities. This workshop focuses on understanding the implications of heterogeneous designs at all levels of the computing system stack, such as hardware, compiler optimizations, porting of applications, and developing programming environments for current and emerging systems in all the above-mentioned areas. It seeks to ground heterogeneous system design research through studies of application kernels and/or whole applications, as well as shed light on new tools, libraries and runtime systems that improve the performance and productivity of applications on heterogeneous systems.</p>

  <p>The goal of this workshop is to bring together researchers and practitioners who are at the forefront of Heterogeneous computing to learn the opportunities and challenges in future Heterogeneous system design trends and thus help influence the next trends in this area.</p>

  <p><b>Topics of interest include</b> (but are not limited to):</p>
  <ul>
    <li>Applications for hybrid/heterogenous systems;</li>
    <li>Strategies for programming heterogeneous systems using high-level models such as OpenMP, OpenACC, SYCL, OneAPI, Kokkos, Raja, and low-level models such as OpenCL, CUDA;</li>
    <li>Methods and tools to tackle challenges from heterogeneity in AI/ML/DL, BigData, Cloud Computing, Edge-Computing, Real-time Systems, and High-Performance Computing;</li>
    <li>Strategies for application behavior characterization and performance optimization for accelerators;</li>
    <li>Techniques for optimizing kernels for execution on GPGPU, FPGA, TPU, DPU and new emerging heterogeneous platforms;</li>
    <li>Models of application performance on heterogeneous and accelerated HPC systems;</li>
    <li>Compiler Optimizations and tuning heterogeneous systems including parallelization, loop transformation, locality optimizations, Vectorization;</li>
    <li>Implications of workload characterization in heterogeneous and accelerated architecture design;</li>
    <li>Benchmarking and performance evaluation for heterogeneous systems at all level of the system stack;</li>
    <li>Tools and techniques to address both performance and correctness to assist application development for accelerators and heterogeneous processors;</li>
    <li>System software techniques to abstract application domain-specific functionalities for accelerators;</li>
    <li>Innovative use of heterogeneous computing in AI for science or optimizations for AI;</li>
    <li>Design and use of domain-specific functionalities on accelerators;</li>
    <li>Hybrid neuromorphic computing systems;</li>
    <li>In-memory architectures;</li>
    <li>Dataflow architectures;</li>
  </ul>

  <p><b>Paper Tracks:</b></p>

  <p>There are two paper tracks available for AsHES’23:</p>
  <ul>
    <li>1) Full paper track (8 - 10 pages) including citations;</li>
    <li>2) Short paper track (maximum of 4 pages) including citations; meant to highlight early investigations of innovative ideas.</li>
  </ul>

  <p>Submitted papers will undergo a single-blind review process, so the authors do not need to anonymize a submission.</p>

</div> <!-- End of Workshop Scope and Goals -->

{% include dates.html %}

<h1>Proceedings</h1>
<div id="description">
  TBD
</div> <!-- End of Proceedings -->

{% include instructions.html %}
{% include journal.html %}

</div> <!-- End of sub-frame -->
